{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How to run Boa:\n",
    "\n",
    "First, you need to install the following things:\n",
    "\n",
    "* Python2.7 or greater\n",
    "* biopython\n",
    "* matplotlib\n",
    "* numpy\n",
    "* panda\n",
    "* bx-python\n",
    "* blastall\n",
    "* hmmer\n",
    "* cdhit\n",
    "* clustalw\n",
    "* nltk\n",
    "* mafft\n",
    "* transeq\n",
    "\n",
    "Most of these can be installed with the following command on Ubuntu. You can run it with shift+enter, it will run on your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo apt-get install python python-biopython python-matplotlib python-panda python-numpy nltk clustalw cd-hit hmmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to also install blastall, mafft, transeq and bx-python.\n",
    "\n",
    "blast can be downloaded from here- \n",
    "ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/\n",
    "\n",
    "mafft can be downloaded from here-\n",
    "http://mafft.cbrc.jp/alignment/software/source.html\n",
    "\n",
    "For transeq, you need to install emboss, which can be downloaded from here (you might need to also install x11 dev\n",
    "files for this, it will show error while installing if you need this)-\n",
    "http://emboss.open-bio.org/html/adm/ch01s01.html\n",
    "\n",
    "bx-python can be installed through the following link: \n",
    "https://bitbucket.org/james_taylor/bx-python/wiki/Home\n",
    "\n",
    "If everything is installed properly, now you can run Boa with the pipeline.py file(inside src folder). Following is the command that you can run from your terminal.\n",
    "\n",
    "```python\n",
    "    python pipeline.py \n",
    "    --root-dir=\"/home/nafizh/Boa_project/Boa\" \n",
    "    --genome-dir=\"/home/nafizh/Boa_project/Boa/boa_genbank_data/\" \n",
    "    --bacteriocins=\"/home/nafizh/Boa_project/Boa/bacteriocins/bagel.fa\" \n",
    "    --intermediate=\"/home/nafizh/Boa_project/Boa/intermediate_me\" \n",
    "    --training-labels=\"/home/nafizh/Boa_project/Boa/data/training/training_proteins.txt\" \n",
    "    --training-directory=\"/home/nafizh/Boa_project/Boa/data/training/protein\" \n",
    "    --formatdb \n",
    "```\n",
    "\n",
    "Here\n",
    "\n",
    "* --root-dir is the folder inside which all code and all experimental data reside. My root directory here is \n",
    "  \"/home/nafizh/Boa_project/Boa\", all my code and data is inside this Boa folder.\n",
    "* --genome-dir is the folder where your bacterial genome files reside.\n",
    "* --bacteriocin is the file(/bacteriocins/bagel.fa) with bacteriocins that are identified by BAGEL3. It is one part of the \"gold standard\" data set.\n",
    "* --intermediate is a directory of your choice where all the files during the process and the result files will be generated.\n",
    "* --training-labels(\"data/training/training_proteins.txt\") is the literature curated dataset.\n",
    "* --traning-directory is the directory that contains all of the genbank files for each curated protein.\n",
    "* --formatdb is required to form a database from experimental bacterial genome files inside --genome-dir. This databased will be run against the --bacteriocin file with blast. This is only required once. So, once run, if you run pipeline.py again, you can ignore it unless your experimental bacterial genome files have changed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How pipeline.py is working:\n",
    "\n",
    "I will try to give a brief overview of what pipeline.py is doing under the hood. It has 5 distinct steps inside the\n",
    "```python\n",
    "    if __name__ == __main__:\n",
    "```\n",
    "function. They are:\n",
    "\n",
    "+ preprocess\n",
    "+ blast\n",
    "+ blastContextGenes\n",
    "+ hmmerGenes\n",
    "+ cliqueFilter\n",
    "\n",
    "\n",
    "1. During the **preprocess** step, these files will be generated using the files inside --genome-dir:\n",
    "   all.faa, all.faaidx, all.fai, all.fna, all.gff, all_trans.fai, all_trans.fna, annotated_genesDB.fa, \n",
    "   intergeneDB.fa.\n",
    "   \n",
    "   For **annotated_genesDB.fa**, preprocess is taking the \"amino acid translation corresponding to the nucleotide \n",
    "   coding  sequence(CDS)\" from each .gbk(genbank - http://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html) file and \n",
    "   putting it inside **annotated_genesDB.fa** with the filename, base span, whether it is in complementary strand \n",
    "   or not, locus tag and protein id.\n",
    "   \n",
    "   The preprocess step also finds the integenic regions and corresponding nucleotides from the .fna(fasta) files\n",
    "   and puts it inside the **intergeneDB.fa** file.\n",
    "   \n",
    "   The other files are result of necessary formatting procedures for future steps.\n",
    "   \n",
    "   preprocess function is using the **annotation.py** and **intergene.py** files to do these.\n",
    "   <br><br>\n",
    "2. The **blast** step is creating a database from the all.fna file with a command -\n",
    "   **\"formatdb -i /home/nafizh/temp/all.fna -p F\"**\n",
    "   \n",
    "   It is then running that database against bagel.fa file with blast(tblastn command specifically). blast function \n",
    "   inside pipeline.py is using **bacteriocin.py** to do all these.\n",
    "   \n",
    "   In this step, files with names like **\"blasted.0.bacteriocins.txt\"** and **\"blasted.0.annotated.txt\"** are\n",
    "   produced.\n",
    "   \n",
    "   The **\"blasted.0.bacteriocins.txt\"** type files are merged into **blasted_bacteriocins.fa** file. It contains \n",
    "   the list of bacteriocins aligned against all of the bacterial genomes provided. It contains the following \n",
    "   things(shown with an example from the file)-\n",
    "   \n",
    "   > \\>80.3|gi|256632183|dbj|AP011121.1|2340005|2340748|-|gene\n",
    "       MNNLHKHLAPISHAAWAEIEQEASRTIRRNLAGRRVVDTPEPKGTAFSSVGTGRNKQI--QSPSDGIQAV---- \n",
    "       QREVLPVIELRVPFTLSRAEIDAVERGSLDSDWQPVKDAAQKIAFAEDRAIFDGYTAAGITGIRQGSSNPHTKLPTSAKDYPRAITNALDTLRLAGVNGPYALV\n",
    "       LGTKAY-QAVSGGDDVGYPVLKHIESLIEGEPIWAPAIEGAFVISKRGGDLQLDIGQDFSIGYLSHTAETVELYLQE\n",
    "      \n",
    "      Here, \n",
    "            80.3 - bacteriocin name\n",
    "            gi|256632183|dbj|AP011121.1 - ncbi id of species blasted against(from .fna file of the species)\n",
    "            2340005 - bacteriocin start\n",
    "            2340748 - bacteriocin end\n",
    "            '-' -  bacteriocin strand\n",
    "            gene - overlaps intergene or gene\n",
    "            MNNLHKHLAPISHAAWAEIEQEASRTIRRNLAGR....... - blasted bacteriocin sequence\n",
    "            \n",
    "   The **\"blasted.0.annotated.txt\"** type files are merged into **cand_context_genes.fa** file. It contains the\n",
    "   list of annotated genes within a radius around all of the blasted bacteriocins. This search radius can be \n",
    "   specified in the bacteriocin.py script. It contains the following things(shown with an example from the file)-\n",
    "   \n",
    "   > \\>80.3|gi|256632183|dbj|AP011121.1|2340005|2340748|-|AP011121|APA01_21470|BAI00262.1|2334839|2335451|+\n",
    "      MVAGCAAFHPLGEARRMGAAARTGSGTTGSGIRNDFSGWHKHQGSPQSGGSPKKGASFEERDHREALGRSRGGYGTKVCVIADGHGKAFGFALAPGQAHELPLAPAM\n",
    "      LDSLPATPLWVVADKGYASNAMRERIWDMGARPAIPAKRRDGPVACPKWAYRCRHLVENLWARLKEWRAVATRYEKTATSFLAVIHIAAAADWIKP\n",
    "      \n",
    "      Here,\n",
    "            80.3 - bacteriocin name\n",
    "            gi|256632183|dbj|AP011121.1 - ncbi id of anchor gene\n",
    "            2340005 - blast bacteriocin start\n",
    "            2340748 - blast bacteriocin end\n",
    "            '-' - blast bacteriocin strand\n",
    "            AP011121|APA01_21470|BAI00262.1 - accession id of whole genome\n",
    "            2334839 - anchor gene start\n",
    "            2335451 - anchor gene end\n",
    "            '+' - anchor gene strand\n",
    "            MVAGCAAFHPLGEARRMGAAARTGSG....  - sequence of bacteriocin\n",
    "   <br><br>         \n",
    "3. The **blastContextGenes** step identifies context genes using BLAST.\n",
    "   \n",
    "   It first splits up the **\"cand_context_genes.fa\"** file to a bunch of **context.0** type of files depending on \n",
    "   the number of njobs provided to the function. Then thr results are put into contextout.0 type files and then put \n",
    "   together into the classify file. So, basically for the blastContextGenes() function-\n",
    "       input: cand_context_genes.fa -> conext.0, context.1 ...\n",
    "       output: contextout.0, contextout.1 ... -> classify\n",
    "   <br><br>    \n",
    "4. The **hmmerGenes** step creates HMMER profiles of all of the blasted context genes and the bacteriocins to find \n",
    "more candidate context genes and bacteriocins.\n",
    "\n",
    "   It is taking the **\"classify\"** file and putting the context genes in \"modifier.fa\", \"immunity.fa\",   \n",
    "   \"transport.fa\", \"regulator.fa\" files.\n",
    "   \n",
    "   Then It is taking the **\"blasted_bacteriocins.fa\"** file and putting the toxins into the **\"toxin.fa\"** file.\n",
    "   \n",
    "   For each type of context genes and bacteriocin, if the number of clusters is equal to or more than the set\n",
    "   **\"min_cluster\"** variable, then **\"toxin.fa.cluster0.fa\"** type files are created with the following line.\n",
    "   \n",
    "   ```python\n",
    "    H.writeClusters(similarity=0.7,memory=3000)\n",
    "   ```\n",
    "   \n",
    "   Then with the following code, it is taking each **\"toxin.fa.cluster0.fa\"** type file, and first, performing\n",
    "   multiple alignment with Muscle on each cluster with MAFFT. Then builds an HMM for each cluster. In this step,\n",
    "   the **\"toxin.fa.cluster0.fa.hmm\"**, **\"toxin.fa.cluster0.fa.sto\"** and **\"toxin.fa.cluster0.fa_hmmbuild.log\"**\n",
    "   type files are created.\n",
    "\n",
    "    \n",
    "   ```python\n",
    "    H.HMMspawn(msa=MAFFT,njobs=njobs)\n",
    "\n",
    "    #this function is within the hmmer.py file\n",
    "    def HMMspawn(self,msa=MAFFT,njobs=4,maxiters=20):\n",
    "        procs = []\n",
    "        i = 0\n",
    "\n",
    "        # number of transport.fa.cluster0.fa type files for each functional category of context genes\n",
    "        print len(self.clusterfas)\n",
    "\n",
    "        #looping over the transport.fa.cluster0.fa type files \n",
    "        for clrfa in self.clusterfas:\n",
    "            hmm = HMM(clrfa,module=self.module,threads=self.threads)\n",
    "            self.hmms.append(hmm)\n",
    "        for hmm in self.hmms:\n",
    "            proc = hmm.multipleAlignment(msa=msa,maxiters=maxiters)\n",
    "            if proc!=None:\n",
    "                procs.append(proc)\n",
    "            i+=1\n",
    "            if i==njobs: #make sure jobs don't overload\n",
    "                self.wait(procs,fasta=True)\n",
    "                procs,i = [],0\n",
    "        self.wait(procs,fasta=True)\n",
    "\n",
    "        procs,i = [],0\n",
    "        for hmm in self.hmms:\n",
    "            proc = hmm.hmmbuild()\n",
    "            procs.append(proc)\n",
    "            i+=1\n",
    "            if i==njobs: #make sure jobs don't overload\n",
    "                self.wait(procs)\n",
    "                procs,i = [],0\n",
    "        self.wait(procs)\n",
    "\n",
    "    #this function is within the hmmer.py file\n",
    "    \"\"\"Perform multiple alignment with Muscle on a single cluster\"\"\"\n",
    "    def multipleAlignment(self,module=subprocess,msa=MAFFT,maxiters=20):\n",
    "        if self.seqcount(self.clusterfa)==1:\n",
    "            self.sto = self.clusterfa\n",
    "            return None\n",
    "        else:\n",
    "            #mafft class in mafft.py is being called - Nafiz\n",
    "            cw = msa(self.clusterfa,self.sto,module)\n",
    "            self.clustal = cw\n",
    "            if msa==Muscle:\n",
    "                proc = cw.run(fasta=True,maxiters=maxiters)\n",
    "            else:\n",
    "                proc = cw.run(fasta=True,maxiters=maxiters,threads=self.threads)\n",
    "            #cw.outputSTO()\n",
    "            return cw\n",
    "\n",
    "    #this function is within the hmmer.py file        \n",
    "    \"\"\"Builds an HMM for a cluster\"\"\"\n",
    "    def hmmbuild(self,module=subprocess):\n",
    "        cmd = \"hmmbuild %s %s \"%(self.hmm,self.sto)\n",
    "        #Changed from self.module.Popen -> module.Popen - Nafiz\n",
    "        proc = subprocess.Popen(cmd, stderr=open(self.logs[0],'w+'),shell=True)\n",
    "        if self.module==quorum: proc.submit()\n",
    "        #proc.wait()\n",
    "        return proc\n",
    "   ``` \n",
    "   \n",
    "   Then with the following code, it is taking the **all.faa** file and the **\\*.out** type files, and performs\n",
    "   HMMER using all clusters on the all.faa file. The **\"toxin.fa.cluster0.fa.table\"** type files are being\n",
    "   created here also. It is writing the results in the **\\*.out** files.\n",
    "   \n",
    "    \n",
    "   ```python\n",
    "    H.search(self.faa,self.hmmer_class_out[i],maxpower=True,njobs=njobs)\n",
    "\n",
    "    #this function is in the hmmer.py file\n",
    "    \"\"\"Performs HMMER using all clusters on infasta\"\"\"\n",
    "    def search(self,infasta,out,maxpower=False,njobs=4):\n",
    "        procs = []\n",
    "        i = 0\n",
    "        for hmm in self.hmms:\n",
    "            proc = hmm.hmmsearch(infasta,maxpower)\n",
    "            self.tables.append(hmm.table)\n",
    "            procs.append(proc)\n",
    "            i+=1\n",
    "            if i==njobs: #make sure jobs don't overload\n",
    "                self.wait(procs)\n",
    "                procs,i = [],0\n",
    "        self.wait(procs)\n",
    "        procs,i = [],0     \n",
    "\n",
    "        with open(out, 'w') as outfile:\n",
    "            for fname in self.tables:\n",
    "                if os.path.exists(fname):\n",
    "                    with open(fname) as infile:\n",
    "                        for line in infile:\n",
    "                            outfile.write(line)\n",
    "    \n",
    "    #this function is in the hmmer.py file\n",
    "    \"\"\"Runs Viterbi algorithm on an input protein fasta\"\"\"\n",
    "    def hmmsearch(self,infasta,maxpower=False):\n",
    "        if maxpower:\n",
    "            cmd = \"hmmsearch --noali --notextw --max --domtblout %s %s %s\"%(self.table,self.hmm,infasta)\n",
    "        else:\n",
    "            cmd = \"hmmsearch --noali --notextw --domtblout %s %s %s\"%(self.table,self.hmm,infasta)\n",
    "        print cmd\n",
    "        # changed - Nafiz\n",
    "        proc = subprocess.Popen(cmd,stderr=open(self.logs[0],'w+'),shell=True)\n",
    "    #    if self.module==quorum: proc.submit() #Nafiz\n",
    "        return proc\n",
    "   ```\n",
    " <br></br>\n",
    "5.The **cliqueFilter** step finds operons by constructing graphs and finding cliques. It takes the \\*.out files as input and outputs the results in the **\"operons.txt\"** and **\"predicted_operons.txt\"** files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from bagel.fa\n",
      "255\n",
      "from blasted_bacteriocins.fa\n",
      "255\n",
      "from cand_context_genes.fa\n",
      "203\n",
      "from AP011121.gbk file\n",
      "264\n",
      "MNLLAPISAWAEIEEATLARVVDPGSSVGRGAVRVPIELVPFTLRAEARGDDPVAAIAAEDRAFGAGITGISLPDPALLRGVGPYALVLGYQGYPVLHLEGIWAPGAISRGGDLGDFSIGYHAVLYLQE\n",
      "129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSo what is haeppening here is, a bacteriocin is taken from bagel- for example- number 80.3 and it is blasted against\\nall genome files. Now for example, against the AP011121.gbk file, there are many translations inside it. The closest\\none is taken and put inside blasted_bacteriocins.fa file. For some .gbk files it is done and for each of them one entry\\nis put in the file.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bacteriocin id - 80.3\n",
    "\n",
    "print \"from bagel.fa\"\n",
    "bagel = 'MNDLMRDLAPISAKAWAEIETEARGTLTVTLAARKVVDFKGPLGWDASSVSLGRTEALAEEPKAAGSAAVVTVRKRAVQPLIELCVPFTLKRAELEAIARGASDADLDPVIEAARAIAIAEDRAVFHGFAAGGITGIGEASAEHALDLPADLADFPGVLVRALAVLRDRGVDGPYALVLGRTVYQQLMETTTPGGYPVLQHVRRLFEGPLIWAPGVDGAMLISQRGGDFELTVGRDFSIGYHDHDAQSVHLYLQE'\n",
    "print len(bagel)\n",
    "\n",
    "print \"from blasted_bacteriocins.fa\"\n",
    "blasted = 'MNNLHKHLAPISHAAWAEIEQEASRTIRRNLAGRRVVDTPEPKGTAFSSVGTGRNKQI--QSPSDGIQAV----QREVLPVIELRVPFTLSRAEIDAVERGSLDSDWQPVKDAAQKIAFAEDRAIFDGYTAAGITGIRQGSSNPHTKLPTSAKDYPRAITNALDTLRLAGVNGPYALVLGTKAY-QAVSGGDDVGYPVLKHIESLIEGEPIWAPAIEGAFVISKRGGDLQLDIGQDFSIGYLSHTAETVELYLQE'\n",
    "print len(blasted)\n",
    "\n",
    "print \"from cand_context_genes.fa\"\n",
    "cand = 'MVAGCAAFHPLGEARRMGAAARTGSGTTGSGIRNDFSGWHKHQGSPQSGGSPKKGASFEERDHREALGRSRGGYGTKVCVIADGHGKAFGFALAPGQAHELPLAPAMLDSLPATPLWVVADKGYASNAMRERIWDMGARPAIPAKRRDGPVACPKWAYRCRHLVENLWARLKEWRAVATRYEKTATSFLAVIHIAAAADWIKP'\n",
    "print len(cand)\n",
    "\n",
    "AP_file = \"MNNLHKHLAPISHAAWAEIEQEASRTIRRNLAGRRVVDTPEPKGTAFSSVGTGRNKQIQSPSDGIQAVQREVLPVIELRVPFTLSRAEIDAVERGSLDSDWQPVKDAAQKIAFAEDRAIFDGYTAAGITGIRQGSSNPHTKLPTSAKDYPRAITNALDTLRLAGVNGPYALVLGTKAYQAVSGGDDVGYPVLKHIESLIEGEPIWAPAIEGAFVISKRGGDLQLDIGQDFSIGYLSHTAETVELYLQESFTFRVLTSEATVCIA\"\n",
    "print \"from AP011121.gbk file\"\n",
    "print len(AP_file)\n",
    "\n",
    "temp = [i for i,j in zip(blasted, bagel) if i == j]\n",
    "print ''.join(temp)\n",
    "print len(temp)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "So what is haeppening here is, a bacteriocin is taken from bagel- for example- number 80.3 and it is blasted against\n",
    "all genome files. Now for example, against the AP011121.gbk file, there are many translations inside it. The closest\n",
    "one is taken and put inside blasted_bacteriocins.fa file. For some .gbk files it is done and for each of them one entry\n",
    "is put in the file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
